{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Acceleration threshold + walking overlap analysis.\n",
    "\n",
    "This notebook loads raw tri-axial accelerometer data (X/Y/Z), constructs a sample-level\n",
    "timestamp series from a known recording start time and sampling frequency, and computes\n",
    "the squared acceleration magnitude:\n",
    "\n",
    "It also loads “Postural Events” exported from PAMWare (Excel) and extracts walking\n",
    "episodes (“Start of Walking”, “End of Walking”, and optionally “Duration of Walking (s)”),\n",
    "with light header/column-name normalization to handle formatting differences.\n",
    "\n",
    "Main output is an interactive Plotly visualization that overlays:\n",
    "\n",
    "Walking episodes as blue time bars\n",
    "Triggered “recording segments” as red time bars (built from threshold crossings)\n",
    "The |a|^2 time series as a line, plus an optional horizontal threshold line\n",
    "Recording segments are generated by scanning the full signal in fixed windows\n",
    "(default 2 s). If the maximum |a|^2 within a window exceeds the threshold, the peak\n",
    "sample becomes a trigger and a segment is created from:\n",
    "\n",
    "record_prev_seconds before the peak, through\n",
    "record_after_seconds after the peak\n",
    "Overlapping/adjacent segments are merged.\n",
    "For the current zoom/view window, the notebook prints summary metrics:\n",
    "\n",
    "total walking episodes\n",
    "total walking duration (s)\n",
    "total recording segments\n",
    "total recorded duration (s)\n",
    "walking episodes overlapped by recording\n",
    "walking duration overlapped by recording (s)\n",
    "Key function:\n",
    "plot_mag2_with_walking_and_recording_bars(...)\n",
    "\n",
    "Returns:\n",
    "(fig, rec_df, metrics_df)\n",
    "- fig: Plotly Figure\n",
    "- rec_df: DataFrame of recording segment Start/End times\n",
    "- metrics_df: DataFrame of summary metrics (with percentages vs walking totals)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7204cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the accelerometer data CSV file\n",
    "path = \"Data/KUBM-002 Acc Data 11-17.csv\"\n",
    "\n",
    "# Path to the postural events data Excel file from PAMWare\n",
    "xlsx_path = \"Data/IBM02_2023_11_17.xlsx\"\n",
    "sheet = \"Postural Events\"\n",
    "\n",
    "fs_hz = 50.0  # sampling frequency\n",
    "recording_start = pd.to_datetime(\"11/17/23 12:00:00 AM\")\n",
    "recording_end_expected = pd.to_datetime(\"11/18/23 12:00:00 AM\") # You can adjust this if needed differen prefferred end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c84b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the accelerometer data table (skip metadata rows above the real header)\n",
    "df = pd.read_csv(\n",
    "    path,\n",
    "    skiprows=7,# rows 0-6 are metadata; row 7 contains the real header\n",
    "    sep=\",\",\n",
    "    skipinitialspace=True,   # trims spaces after commas in header + values\n",
    "    engine=\"python\",\n",
    " )\n",
    "\n",
    "# Keep just X/Y/Z if that's all you need (optional):\n",
    "df_xyz = df[[\"X\", \"Y\", \"Z\"]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Build a timestamp for every sample based on start time + fs\n",
    "\n",
    "n = len(df_xyz)\n",
    "t = recording_start + pd.to_timedelta(np.arange(n) / fs_hz, unit=\"s\")\n",
    "df_xyz_time = df_xyz.copy()\n",
    "df_xyz_time[\"Time\"] = t\n",
    "\n",
    "df_xyz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: downsample for faster plotting on large files\n",
    "plot_df = df_xyz\n",
    "max_points = 2705951\n",
    "if len(plot_df) > max_points:\n",
    "    step = max(1, len(plot_df) // max_points)\n",
    "    plot_df = plot_df.iloc[::step]\n",
    "\n",
    "# Squared magnitude (in g^2 if X/Y/Z are in g)\n",
    "mag2 = (plot_df[\"X\"] ** 2) + (plot_df[\"Y\"] ** 2) + (plot_df[\"Z\"] ** 2)\n",
    "threshold_g2 = 1.44\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(plot_df.index, plot_df[\"X\"], color=\"blue\", linewidth=1, label=\"X\")\n",
    "plt.plot(plot_df.index, plot_df[\"Y\"], color=\"red\", linewidth=1, label=\"Y\")\n",
    "plt.plot(plot_df.index, plot_df[\"Z\"], color=\"green\", linewidth=1, label=\"Z\")\n",
    "\n",
    "# Plot squared magnitude + threshold line\n",
    "#plt.plot(plot_df.index, mag2, color=\"black\", linewidth=1, alpha=0.8, label=r\"|a|$^2$ (X$^2$+Y$^2$+Z$^2$)\")\n",
    "plt.axhline(threshold_g2, color=\"purple\", linestyle=\"--\", linewidth=1.5, label=r\"Threshold = 1.44 g$^2$\")\n",
    "\n",
    "plt.title(\"Acceleration (X/Y/Z) + Squared Magnitude over Samples\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Acceleration (g) / Squared Magnitude (g$^2$)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(ncols=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _norm_col(name: str) -> str:\n",
    "    s = \"\" if name is None else str(name)\n",
    "    s = s.strip().lower()\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "\n",
    "targets = {\n",
    "    \"Start of Walking\": _norm_col(\"Start of Walking\"),\n",
    "    \"End of Walking\": _norm_col(\"End of Walking\"),\n",
    "    \"Duration of Walking (s)\": _norm_col(\"Duration of Walking (s)\"),\n",
    "}\n",
    "\n",
    "def _read_with(header, skiprows):\n",
    "    df = pd.read_excel(\n",
    "        xlsx_path,\n",
    "        sheet_name=sheet,\n",
    "        header=header,\n",
    "        skiprows=skiprows,\n",
    "        engine=\"openpyxl\",\n",
    "    )\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "# 1) Try exactly what you requested (pandas uses 0-based row indices).\n",
    "postural = _read_with(header=2, skiprows=[1, 3])\n",
    "\n",
    "# 2) If expected columns are not present, auto-detect the header row from the first ~20 rows.\n",
    "normed_cols = {_norm_col(c) for c in postural.columns}\n",
    "if not set(targets.values()).issubset(normed_cols):\n",
    "    preview = pd.read_excel(\n",
    "        xlsx_path,\n",
    "        sheet_name=sheet,\n",
    "        header=None,\n",
    "        nrows=25,\n",
    "        engine=\"openpyxl\",\n",
    "    )\n",
    "    header_row = None\n",
    "    for r in range(len(preview)):\n",
    "        row_vals = [_norm_col(v) for v in preview.iloc[r].tolist()]\n",
    "        if all(t in row_vals for t in targets.values()):\n",
    "            header_row = r\n",
    "            break\n",
    "    if header_row is None:\n",
    "        raise KeyError(\n",
    "            \"Could not find a header row containing the expected columns. \"\n",
    "            f\"Available columns from first attempt: {list(postural.columns)}\"\n",
    "        )\n",
    "    postural = pd.read_excel(\n",
    "        xlsx_path,\n",
    "        sheet_name=sheet,\n",
    "        header=header_row,\n",
    "        engine=\"openpyxl\",\n",
    "    )\n",
    "    postural.columns = postural.columns.astype(str).str.strip()\n",
    "\n",
    "# Build a lookup from normalized column name -> actual column name\n",
    "col_lookup = {_norm_col(c): c for c in postural.columns}\n",
    "walk_events = postural.loc[:, [col_lookup[targets[k]] for k in targets]].copy()\n",
    "\n",
    "walk_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42350233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_mag2_with_walking_and_recording_bars(\n",
    "    df_xyz: pd.DataFrame,\n",
    "    walk_events: pd.DataFrame,\n",
    "    df_xyz_time: pd.DataFrame | None = None,\n",
    "    fs_hz: float = 50,\n",
    "    recording_start: str | pd.Timestamp = \"01/08/24 08:58:00 AM\",\n",
    "    zoom_start: str | pd.Timestamp | None = None,\n",
    "    zoom_end: str | pd.Timestamp | None = None,\n",
    "    max_points: int = 200_000,\n",
    "    threshold_g2: float | None = 1.44,\n",
    "    bar_height_g2: float = 3.0,          # walking bar height (g^2 units)\n",
    "    rec_bar_height_g2: float = 0.6,      # recording bar height (smaller)\n",
    "    check_window_seconds: float = 2.0,   # peak check window length\n",
    "    record_prev_seconds: float = 2.0,    # record previous 2s FROM PEAK SAMPLE\n",
    "    record_after_seconds: float = 15.0,  # record next 15s FROM PEAK SAMPLE\n",
    "    show_peak_markers: bool = True,      # debug: show detected peak triggers\n",
    "):\n",
    "    \"\"\"\n",
    "    One Plotly graph:\n",
    "      - mag2 line (same a2 used for detection)\n",
    "      - walking bars (blue)\n",
    "      - recording bars (red)\n",
    "\n",
    "    Also prints 6 metrics UNDER the graph (for the current zoom window):\n",
    "      1) total walking episodes\n",
    "      2) total walking duration (s)\n",
    "      3) total recording segments (red boxes)\n",
    "      4) total recorded time (s)\n",
    "      5) walking episodes overlapped by recording\n",
    "      6) walking duration overlapped by recording (s)\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build/validate timebase\n",
    "    # -----------------------------\n",
    "    if df_xyz_time is None:\n",
    "        if df_xyz is None or len(df_xyz) == 0:\n",
    "            raise ValueError(\"df_xyz must be a non-empty DataFrame.\")\n",
    "        if not {\"X\", \"Y\", \"Z\"}.issubset(df_xyz.columns):\n",
    "            raise ValueError(\"df_xyz must contain columns: X, Y, Z\")\n",
    "\n",
    "        start_ts = pd.to_datetime(recording_start)\n",
    "        n = len(df_xyz)\n",
    "        df_xyz_time = df_xyz.copy()\n",
    "        df_xyz_time[\"Time\"] = start_ts + pd.to_timedelta(np.arange(n) / fs_hz, unit=\"s\")\n",
    "        fs_eff = float(fs_hz)\n",
    "    else:\n",
    "        if \"Time\" not in df_xyz_time.columns:\n",
    "            raise ValueError(\"df_xyz_time must contain a 'Time' column.\")\n",
    "        if not {\"X\", \"Y\", \"Z\"}.issubset(df_xyz_time.columns):\n",
    "            raise ValueError(\"df_xyz_time must contain columns: Time, X, Y, Z\")\n",
    "\n",
    "        df_xyz_time = df_xyz_time.copy()\n",
    "        df_xyz_time[\"Time\"] = pd.to_datetime(df_xyz_time[\"Time\"], errors=\"coerce\")\n",
    "        if df_xyz_time[\"Time\"].isna().all():\n",
    "            raise ValueError(\"df_xyz_time['Time'] could not be parsed into datetimes.\")\n",
    "\n",
    "        dt = df_xyz_time[\"Time\"].diff().dt.total_seconds().to_numpy()\n",
    "        dt = dt[np.isfinite(dt) & (dt > 0)]\n",
    "        fs_eff = float(1.0 / np.median(dt)) if dt.size else float(fs_hz)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Numeric X/Y/Z + a2 (same for plot + detection)\n",
    "    # -----------------------------\n",
    "    df_mag = df_xyz_time[[\"Time\", \"X\", \"Y\", \"Z\"]].copy()\n",
    "    for c in [\"X\", \"Y\", \"Z\"]:\n",
    "        df_mag[c] = pd.to_numeric(df_mag[c], errors=\"coerce\")\n",
    "\n",
    "    x = np.nan_to_num(df_mag[\"X\"].to_numpy(dtype=np.float32, copy=False), nan=0.0)\n",
    "    y = np.nan_to_num(df_mag[\"Y\"].to_numpy(dtype=np.float32, copy=False), nan=0.0)\n",
    "    z = np.nan_to_num(df_mag[\"Z\"].to_numpy(dtype=np.float32, copy=False), nan=0.0)\n",
    "\n",
    "    a2 = x * x + y * y + z * z\n",
    "    df_mag[\"mag2\"] = a2\n",
    "    n = int(a2.shape[0])\n",
    "    if n == 0:\n",
    "        raise ValueError(\"No samples found.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Episodes (walking)\n",
    "    # -----------------------------\n",
    "    episodes = walk_events.copy()\n",
    "    if not {\"Start of Walking\", \"End of Walking\"}.issubset(episodes.columns):\n",
    "        raise ValueError(\"walk_events must contain columns: 'Start of Walking', 'End of Walking'\")\n",
    "\n",
    "    episodes[\"Start of Walking\"] = pd.to_datetime(episodes[\"Start of Walking\"], errors=\"coerce\")\n",
    "    episodes[\"End of Walking\"] = pd.to_datetime(episodes[\"End of Walking\"], errors=\"coerce\")\n",
    "    episodes = (\n",
    "        episodes.dropna(subset=[\"Start of Walking\", \"End of Walking\"])\n",
    "        .sort_values(\"Start of Walking\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    if episodes.empty:\n",
    "        raise ValueError(\"No valid walking episodes found after parsing Start/End times.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Zoom parsing\n",
    "    # -----------------------------\n",
    "    def _parse_zoom(value, default_date: pd.Timestamp):\n",
    "        if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "            return None\n",
    "        s = str(value).strip()\n",
    "        if not s:\n",
    "            return None\n",
    "        dtv = pd.to_datetime(s, errors=\"coerce\")\n",
    "        if pd.isna(dtv):\n",
    "            return None\n",
    "        if dtv.date() == pd.Timestamp(\"1970-01-01\").date():\n",
    "            dtv = pd.Timestamp.combine(default_date.date(), dtv.time())\n",
    "        return dtv\n",
    "\n",
    "    default_date = episodes[\"Start of Walking\"].iloc[0]\n",
    "    z0 = _parse_zoom(zoom_start, default_date)\n",
    "    z1 = _parse_zoom(zoom_end, default_date)\n",
    "\n",
    "    x0 = z0 if z0 is not None else episodes[\"Start of Walking\"].iloc[0]\n",
    "    x1 = z1 if z1 is not None else episodes[\"End of Walking\"].iloc[-1]\n",
    "    if x1 < x0:\n",
    "        raise ValueError(\"zoom_end must be after zoom_start\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Peak-preserving decimation (min+max per bin)\n",
    "    # -----------------------------\n",
    "    mag_view = df_mag[(df_mag[\"Time\"] >= x0) & (df_mag[\"Time\"] <= x1)].copy()\n",
    "    if len(mag_view) > max_points:\n",
    "        step = max(1, len(mag_view) // max_points)\n",
    "        idx = np.arange(len(mag_view))\n",
    "        grp = idx // step\n",
    "        g = mag_view.groupby(grp, sort=False)[\"mag2\"]\n",
    "        keep = np.unique(np.concatenate([g.idxmax().to_numpy(), g.idxmin().to_numpy()]))\n",
    "        mag_view = mag_view.loc[keep].sort_index()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Walking bars (within view)\n",
    "    # -----------------------------\n",
    "    ep_view = episodes[(episodes[\"End of Walking\"] >= x0) & (episodes[\"Start of Walking\"] <= x1)].copy()\n",
    "    ep_dur_s = (ep_view[\"End of Walking\"] - ep_view[\"Start of Walking\"]).dt.total_seconds()\n",
    "    ep_mid = ep_view[\"Start of Walking\"] + (ep_view[\"End of Walking\"] - ep_view[\"Start of Walking\"]) / 2\n",
    "    ep_width_ms = ep_dur_s * 1000.0\n",
    "\n",
    "    # -----------------------------\n",
    "    # Recording segments (FULL series, then filter to view)\n",
    "    # -----------------------------\n",
    "    rec_df = pd.DataFrame(columns=[\"Start\", \"End\"])\n",
    "    peak_times_in_view = None\n",
    "\n",
    "    if threshold_g2 is not None:\n",
    "        check_n = int(round(fs_eff * check_window_seconds))\n",
    "        prev_n = int(round(fs_eff * record_prev_seconds))\n",
    "        after_n = int(round(fs_eff * record_after_seconds))\n",
    "\n",
    "        total_full_windows = n // check_n\n",
    "\n",
    "        segments = []      # [start_idx, end_idx) end exclusive\n",
    "        peak_indices = []\n",
    "        current_end = None\n",
    "\n",
    "        for w in range(total_full_windows):\n",
    "            w_start = w * check_n\n",
    "            block = a2[w_start : w_start + check_n]\n",
    "            if block.size == 0:\n",
    "                continue\n",
    "\n",
    "            peak_val = float(np.max(block))\n",
    "            if peak_val < float(threshold_g2):\n",
    "                continue\n",
    "\n",
    "            peak_off = int(np.argmax(block))\n",
    "            peak_idx = w_start + peak_off\n",
    "            peak_indices.append(peak_idx)\n",
    "\n",
    "            seg_start = peak_idx - prev_n\n",
    "            seg_end = peak_idx + after_n  # 2s before peak + 15s after peak = 17s total\n",
    "\n",
    "            if current_end is None or seg_start >= current_end:\n",
    "                current_end = seg_end\n",
    "                segments.append([seg_start, seg_end])\n",
    "            else:\n",
    "                if seg_end > current_end:\n",
    "                    current_end = seg_end\n",
    "                    segments[-1][1] = current_end\n",
    "\n",
    "        # cap + merge\n",
    "        capped = []\n",
    "        for s0, s1 in segments:\n",
    "            s0_c = max(0, min(n, int(s0)))\n",
    "            s1_c = max(0, min(n, int(s1)))\n",
    "            if s1_c > s0_c:\n",
    "                capped.append((s0_c, s1_c))\n",
    "\n",
    "        capped.sort()\n",
    "        merged = []\n",
    "        for s0, s1 in capped:\n",
    "            if not merged or s0 > merged[-1][1]:\n",
    "                merged.append([s0, s1])\n",
    "            else:\n",
    "                merged[-1][1] = max(merged[-1][1], s1)\n",
    "        merged = [(a, b) for a, b in merged]\n",
    "\n",
    "        t0 = pd.to_datetime(df_mag[\"Time\"].iloc[0])\n",
    "        rec_starts = [t0 + pd.to_timedelta(s0 / fs_eff, unit=\"s\") for s0, _ in merged]\n",
    "        rec_ends = [t0 + pd.to_timedelta(s1 / fs_eff, unit=\"s\") for _, s1 in merged]\n",
    "\n",
    "        rec_df = pd.DataFrame({\"Start\": rec_starts, \"End\": rec_ends})\n",
    "        rec_df = rec_df[(rec_df[\"End\"] >= x0) & (rec_df[\"Start\"] <= x1)].copy()\n",
    "\n",
    "        rec_dur_s = (rec_df[\"End\"] - rec_df[\"Start\"]).dt.total_seconds()\n",
    "        rec_mid = rec_df[\"Start\"] + (rec_df[\"End\"] - rec_df[\"Start\"]) / 2\n",
    "        rec_width_ms = rec_dur_s * 1000.0\n",
    "\n",
    "        if show_peak_markers and peak_indices:\n",
    "            peak_times = [t0 + pd.to_timedelta(i / fs_eff, unit=\"s\") for i in peak_indices]\n",
    "            peak_vals = [a2[i] for i in peak_indices]\n",
    "            peak_times_in_view = [\n",
    "                (pt, pv) for pt, pv in zip(peak_times, peak_vals) if (pt >= x0 and pt <= x1)\n",
    "            ]\n",
    "    else:\n",
    "        rec_mid = np.array([])\n",
    "        rec_width_ms = np.array([])\n",
    "        rec_dur_s = np.array([])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plot\n",
    "    # -----------------------------\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # walking bars\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=ep_mid,\n",
    "            y=np.full(len(ep_view), float(bar_height_g2)),\n",
    "            width=ep_width_ms,\n",
    "            name=\"Walking episode\",\n",
    "            marker=dict(\n",
    "                color=\"rgba(76,120,168,0.20)\",\n",
    "                line=dict(color=\"rgba(47,75,124,0.7)\", width=1),\n",
    "            ),\n",
    "            customdata=np.stack(\n",
    "                [\n",
    "                    ep_view[\"Start of Walking\"].astype(str),\n",
    "                    ep_view[\"End of Walking\"].astype(str),\n",
    "                    ep_dur_s.to_numpy(),\n",
    "                ],\n",
    "                axis=1,\n",
    "            ),\n",
    "            hovertemplate=(\n",
    "                \"Walking<br>\"\n",
    "                \"Start: %{customdata[0]}<br>\"\n",
    "                \"End: %{customdata[1]}<br>\"\n",
    "                \"Duration: %{customdata[2]:.1f} s\"\n",
    "                \"<extra></extra>\"\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # recording bars\n",
    "    if len(rec_df) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=rec_mid,\n",
    "                y=np.full(len(rec_df), float(rec_bar_height_g2)),\n",
    "                width=rec_width_ms,\n",
    "                name=\"Recording segment\",\n",
    "                marker=dict(\n",
    "                    color=\"rgba(220,53,69,0.35)\",\n",
    "                    line=dict(color=\"rgba(180,30,45,0.85)\", width=1),\n",
    "                ),\n",
    "                customdata=np.stack(\n",
    "                    [\n",
    "                        rec_df[\"Start\"].astype(str),\n",
    "                        rec_df[\"End\"].astype(str),\n",
    "                        rec_dur_s.to_numpy(),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                ),\n",
    "                hovertemplate=(\n",
    "                    \"Recording<br>\"\n",
    "                    \"Start: %{customdata[0]}<br>\"\n",
    "                    \"End: %{customdata[1]}<br>\"\n",
    "                    \"Duration: %{customdata[2]:.1f} s\"\n",
    "                    \"<extra></extra>\"\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # mag2 line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mag_view[\"Time\"],\n",
    "            y=mag_view[\"mag2\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"|a|^2 (g^2)\",\n",
    "            line=dict(color=\"black\", width=1),\n",
    "            hovertemplate=\"%{x}<br>|a|^2: %{y:.3f} g^2<extra></extra>\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # peak markers (debug)\n",
    "    if peak_times_in_view:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[t for t, _ in peak_times_in_view],\n",
    "                y=[v for _, v in peak_times_in_view],\n",
    "                mode=\"markers\",\n",
    "                name=\"Detected peak triggers\",\n",
    "                marker=dict(size=6, color=\"red\"),\n",
    "                hovertemplate=\"%{x}<br>peak |a|^2: %{y:.3f} g^2<extra></extra>\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # threshold line\n",
    "    if threshold_g2 is not None:\n",
    "        fig.add_hline(\n",
    "            y=float(threshold_g2),\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"purple\",\n",
    "            annotation_text=f\"{threshold_g2:.2f} g^2\",\n",
    "            annotation_position=\"top right\",\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Walking (Blue) + Recording (Red) + |a|^2 (fs≈{fs_eff:.2f} Hz)\",\n",
    "        barmode=\"overlay\",\n",
    "        height=540,\n",
    "        margin=dict(l=50, r=50, t=60, b=45),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    )\n",
    "    fig.update_xaxes(range=[x0, x1], showgrid=True, title_text=\"Time\", rangeslider_visible=True)\n",
    "    fig.update_yaxes(showgrid=True, title_text=\"|a|^2 (g^2)\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "       # -----------------------------\n",
    "    # Metrics (for this zoom window)\n",
    "    # -----------------------------\n",
    "    # Total walking episodes & duration (within zoom window)\n",
    "    total_walk_episodes = int(len(ep_view))\n",
    "    total_walk_duration_s = float(ep_dur_s.sum())\n",
    "\n",
    "    # Total recording segments & duration (within zoom window)\n",
    "    total_rec_segments = int(len(rec_df))\n",
    "    total_rec_duration_s = float(rec_dur_s.sum()) if len(rec_df) else 0.0\n",
    "\n",
    "    # Overlap metrics\n",
    "    rec_intervals = [\n",
    "        (s.to_pydatetime(), e.to_pydatetime())\n",
    "        for s, e in zip(rec_df[\"Start\"], rec_df[\"End\"])\n",
    "    ] if len(rec_df) else []\n",
    "\n",
    "    def overlap_seconds(ep_start: pd.Timestamp, ep_end: pd.Timestamp, intervals) -> float:\n",
    "        if ep_end <= ep_start or not intervals:\n",
    "            return 0.0\n",
    "        total = 0.0\n",
    "        for rs, re in intervals:\n",
    "            a = max(ep_start.to_pydatetime(), rs)\n",
    "            b = min(ep_end.to_pydatetime(), re)\n",
    "            if b > a:\n",
    "                total += (b - a).total_seconds()\n",
    "        return float(total)\n",
    "\n",
    "    overlap_dur_s = []\n",
    "    overlapped_flags = []\n",
    "\n",
    "    for s, e in zip(ep_view[\"Start of Walking\"], ep_view[\"End of Walking\"]):\n",
    "        ov = overlap_seconds(s, e, rec_intervals)\n",
    "        overlap_dur_s.append(ov)\n",
    "        overlapped_flags.append(ov > 0)\n",
    "\n",
    "    overlap_walk_duration_s = float(np.sum(overlap_dur_s))\n",
    "    overlap_walk_episodes = int(np.sum(overlapped_flags))\n",
    "\n",
    "       # -----------------------------\n",
    "    # Percentages (walking = 100%)\n",
    "    # -----------------------------\n",
    "    ep_pct = lambda x: (x / total_walk_episodes * 100.0) if total_walk_episodes else np.nan\n",
    "    dur_pct = lambda x: (x / total_walk_duration_s * 100.0) if total_walk_duration_s else np.nan\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Metric\": [\n",
    "                \"Total walking episodes (blue)\",\n",
    "                \"Total walking duration (s) (blue)\",\n",
    "                \"Total recording segments (red)\",\n",
    "                \"Total recorded duration (s) (red)\",\n",
    "                \"Walking episodes overlapped by recording\",\n",
    "                \"Walking duration overlapped by recording (s)\",\n",
    "            ],\n",
    "            \"Value\": [\n",
    "                total_walk_episodes,\n",
    "                total_walk_duration_s,\n",
    "                total_rec_segments,\n",
    "                total_rec_duration_s,\n",
    "                overlap_walk_episodes,\n",
    "                overlap_walk_duration_s,\n",
    "            ],\n",
    "            \"Percent (%)\": [\n",
    "                100.0,                                # baseline\n",
    "                100.0,                                # baseline\n",
    "                ep_pct(total_rec_segments),           # <-- FIXED\n",
    "                dur_pct(total_rec_duration_s),\n",
    "                ep_pct(overlap_walk_episodes),\n",
    "                dur_pct(overlap_walk_duration_s),\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    return fig, rec_df, metrics_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# READY-TO-USE EXAMPLE\n",
    "# -----------------------\n",
    "fig, rec_df, metrics_df = plot_mag2_with_walking_and_recording_bars(\n",
    "    df_xyz=df_xyz,\n",
    "    walk_events=walk_events,\n",
    "    df_xyz_time=df_xyz_time,\n",
    "    fs_hz=fs_hz,                 \n",
    "    recording_start=recording_start,\n",
    "    zoom_start=None,\n",
    "    zoom_end=None,\n",
    "    max_points=200_000,\n",
    "    threshold_g2=1.44, # squared g threshold for detection you can adjust this as needed\n",
    "    bar_height_g2=5.0,\n",
    "    rec_bar_height_g2=1.0,\n",
    "    check_window_seconds=2.0,\n",
    "    record_prev_seconds=2.0,\n",
    "    record_after_seconds=15.0,\n",
    "    show_peak_markers=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
